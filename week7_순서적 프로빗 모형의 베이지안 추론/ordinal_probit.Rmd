---
title: "HW7"
output: word_document
---

```{r}
# set
pacman::p_load(mcmc, rjags, runjags, dplyr, ggplot2, mvtnorm, truncnorm)
setwd('C:/Users/dnskd/Desktop/20Spring/Bayesian/week7')
rm(list=ls())
```

```{r}
# 예제 7.1
data<-c(1,1,1,1,1,5,1,1,3,1,1,2,1,0,2,1,1,1,1,0,1,1,1,2,1,1,2,1,1,4,
        1,0,1,1,0,2,2,1,3,2,0,4,2,1,2,2,0,1,2,1,5,2,1,2,2,0,3,2,1,3,
        2,1,5,2,0,2,2,1,2,2,1,1,3,0,1,3,1,3,3,0,2,3,0,5,3,1,4,3,0,3,
        3,0,2,4,1,5,4,1,2,4,1,4,4,0,3,4,0,3,4,0,3,4,1,5,4,0,5,4,0,5)

n <- 40
data <- matrix(data, n, 3, byrow = T)
stress <- data[, 1]
SES <- data[, 2]
mental <- data[ ,3]
ftable(stress, SES, mental)
X <- cbind(rep(1, n), stress, SES, stress*SES)
p <- ncol(X)
y <- mental
nLevels <- 5
nData <- length(y)
dimBeta <- ncol(X)

K <- 5
# Prior
gamma0 <- rep(0, K); sigma0 <- rep(10, K)

# initial
beta <- rep(0, p)
freq.y <- data.frame(table(y))$Freq
prob <- freq.y/sum(freq.y)
gamma <- rep(0, K)
gamma[1] <- 0; gamma[K] <- Inf
for(i in 2:(K-1)){
  gamma[i] <- qnorm(sum(prob[1:i]), 0, 10)
  if(gamma[i] <= gamma[i-1]) gamma[i] <- gamma[i-1] + 0.1
}

z <- rep(0, n)


```


#### Start MCMC ####
```{r, eval =FALSE}

nwarm <- 5000; maxn <- 10000; nthin <- 100
beta.sim <- NULL
gamma.sim <- NULL

for(isim in 1:(nwarm + maxn*nthin)){
  #generate z
  for(i in 1:n){
    if(y[i]==1) z[i] <- rtruncnorm(1, -Inf, gamma[1], X[i,]%*%beta, 1)
  for(k in 2:K)
    if(y[i]==k) z[i] <- rtruncnorm(1, gamma[k-1], gamma[k], X[i,]%*%beta, 1)
  }


# generate beta
var.beta <- n/(n+1)*solve(t(X)%*%X)
mean.beta <- n/(n+1)*solve(t(X)%*%X) %*% (t(X)%*%z)
beta <- as.vector(rmvnorm(1, mean.beta, var.beta))


# generate gamma
gamma[1] <- 0; gamma[K] <- Inf
for(k in 2:(K-1)){
  ak <- max(max(z[y==k]), gamma[k-1])
  bk <- min(min(z[y==k+1]), gamma[k+1])
  gamma[k] <- rtruncnorm(1, ak, bk, gamma0[k], sigma0[k])
}


if(isim>nwarm & isim %%nthin==0){
  beta.sim <- rbind(beta.sim, beta)
  gamma.sim <- rbind(gamma.sim, gamma)
  }

}
#### End MCMC ####

#### Fig 7.2 연속된 1000개의 표본에서 회귀계수 gamma의 경로그림 ####
par(mfrow=c(3,1))
for(i in 2:(K-1)){
  plot(gamma.sim[1:1000, i], type = 'l', xlab = 'iteration', ylab = "gamma")
}

#### Fig 7.3 매 100번째의 표본을 취했을 때 회귀계수 Beta의 경로그림 ####
par(mfrow = c(2,2))
for(i in 1:p){
  plot(beta.sim[,i], type = 'l', xlab ='iteration', ylab = paste0("beta", i))
}

#### Fig 7.4 매 100번째의 표본을 취했을 때 회귀계수 gamma의 경로그림 ####
par(mfrow = c(3,1))
for(i in 2:(K-1)){
  plot(gamma.sim[,i], type = 'l', xlab = 'iteration', ylab = paste0('gamma', i))
}

#### Fig 7.5 beta의 주변 사후분포 ####
par(mfrow=c(2,2))
for(i in 1:p){
  plot(density(beta.sim[,i]), type = 'l', xlab = paste0("beta", i), main = "posterior")
  abline(v = 0, lty = 2, col = 2)
}

#### Fig 7.6 gamma의 주변 사후분포 ####
par(mfrow = c(1,3))
for(i in 2:(K-1)){
  plot(density(gamma.sim[,i]), type = 'l', xlab = paste0("gamma",i), main = "posterior")
}

#### Fig 7.7 gamma_k - gamma_k-1의 주변 사후분포 ####
par(mfrow=c(1,3))
plot(density(gamma.sim[,2]-gamma.sim[,1]), type = 'l', xlab = 'gamma2-gamma1', main = 'posterior')
plot(density(gamma.sim[,3]-gamma.sim[,2]), type = 'l', xlab = 'gamma3-gamma2', main = 'posterior')
plot(density(gamma.sim[,4]-gamma.sim[,3]), type = 'l', xlab = 'gamma4-gamma3', main = 'posterior')

mean.gamma <- rep(0, K)
for(i in 1:K) mean.gamma[i] <- mean(gamma.sim[,i])

mean.beta <- rep(0, p)
for(i in 1:p)mean.beta[i] <- mean(beta.sim[,i])


#write.csv(gamma.sim, "gamma_sim.csv")
#write.csv(beta.sim, "beta_sim.csv")
```

### JAGS 활용
```{r}
modelString = "
model{
for(i in 1:nData){
  y[i] ~ dcat(pr[i, 1:K])
  mu[i] <- inprod(X[i,], beta[])
  pr[i,1] <- phi((gamma1-mu[i]))
  pr[i, 2] <- phi(gamma[2] -mu[i]) - phi(gamma1-mu[i])
  for(k in 3:(K-1)){
    pr[i,k] <- phi(gamma[k]-mu[i]) - phi(gamma[k-1] - mu[i])
  }
  pr[i,K] <- 1 - phi(gamma[K-1]-mu[i])
}

beta[1:dimBeta] ~ dmnorm(muBeta, TauBeta)

gamma1 <- 0

muGamma <- 1; tauGamma <- 0.01
for(k in 1:(K-1)){
  gamma0[k] ~ dnorm(muGamma, tauGamma)T(0,)
}
gamma[1:(K-1)] <- sort(gamma0)
}
"

writeLines(modelString, "model_ordProbit.txt")


X <- cbind(rep(1,n), stress, SES, stress*SES)
y <- mental
nLevels <- 5
nData <- length(y)
dimBeta <- ncol(X)
muBeta <- solve(t(X) %*% X) %*% t(X) %*% y
TauBeta <- 1/nData * t(X) %*% X
dataList <- list(nData = nData, K = nLevels, dimBeta = dimBeta, X = X, y = y, muBeta = muBeta, TauBeta = TauBeta)
betaInit <- rep(0, dimBeta)
gammaInit <- c(0:(nLevels-2)) + 0.5
initsList = list(beta = betaInit, gamma0 = gammaInit)

nChains = 3
jagsModel = jags.model(file = "model_ordProbit.txt", data = dataList, inits = initsList, n.chains = 3, n.adapt = 1000)
update(jagsModel, n.iter = 10000)
codaSamples = coda.samples(jagsModel, variable.names = c("gamma[2:4]", "beta"), thin = 1, n.iter = 10000)

convDiag.plot = function(codaSamples, var){
  ESS = effectiveSize(codaSamples[, var])
  par(mfrow = c(1,2))
  traceplot(codaSamples[, var], xlab = var)
  acf(as.matrix(codaSamples[,var]), main = paste0("ESS=", round(ESS,2)))
}

convDiag = function(codaSamples){
  ESS = effectiveSize(codaSamples); cat("ESS = ", ESS, "\n")
  acceptRate = 1-rejectionRate(codaSamples); cat("Accept rate=", acceptRate, "\n")
  gelman = gelman.diag(codaSamples); print(gelman)
  gelman.1 = as.matrix(gelman$psrf)
  if(max(gelman.1)>1.1) cat("Warning : Gelman Shrink Factor > 1.1", "\n")
  gelman.2 = gelman$mpsrf
  if(gelman.2>1.1) cat("Warning : Gelman Multivariate Shrink Factor > 1.1", "\n")
}

var = colnames(codaSamples[[1]])
par(mfrow = c(length(var), 2))
for(i in 1:length(var))convDiag.plot(codaSamples, var[i])
convDiag(codaSamples)

#### Fig 7.10 JAGS 표본으로부터 추정된 모수의 사후분포 #####
mcmcSamples = as.matrix(codaSamples)
par(mfrow = c(1,1))
plot(density(mcmcSamples[,"beta[2]"]), xlim = c(min(mcmcSamples[, 2:4]), max(mcmcSamples[, 2:4])), main = "", xlab = "beta")
text(1.5, 1.5, "beta2")
lines(density(mcmcSamples[, "beta[3]"]), col = 2)
text(2, 0.5, "beta3", col = 2)
lines(density(mcmcSamples[, "beta[4]"]), col = 3)
text(-1, 1, "beta4", col = 3)
par(mfrow = c(1,1))
plot(density(mcmcSamples[, "gamma[2]"]), xlim = c(min(mcmcSamples[,5:7]), max(mcmcSamples[, 5:7])), main = "", xlab = "gamma")
text(0.5, 1.2, "gamma2")
lines(density(mcmcSamples[, "gamma[3]"]), col = 2)
text(1.8, 1.4, "gamma3", col = 2)
lines(density(mcmcSamples[,"gamma[4]"]), col = 3)
text(2.6, 1.2, "gamma4", col = 3)

para.hat <- apply(mcmcSamples, 2, mean)
para.hat

HPD <- apply(mcmcSamples, 2, function(x) quantile(x, c(0.025, 0.975)))
HPD
```

## 자료의 표준화
```{r}
modelString="
data{
zX[1:nData, 1] = X[1:nData, 1]
for(j in 2:dimBeta){
Xm[j] <- mean(X[,j])
Xsd[j] <- sd(X[,j])
for(i in 1:nData){
zX[i,j] <- (X[i,j]-Xm[j])/Xsd[j]
}
}
}

model{
for(i in 1:nData){
y[i] ~ dcat(pr[i, 1:K])
pr[i, 1] <- phi((gamma1 - mu[i]))
pr[i, 2] <- max(0, phi(gamma[2] - mu[i]) - phi(gamma1 - mu[i]))

for(k in 3:(K-1)){
pr[i,k] <- max(0, phi(gamma[k]-mu[i]) - phi(gamma[k-1]-mu[i]))
}
pr[i,K] <- 1-phi(gamma[K-1]-mu[i])
mu[i] <- inprod(zX[i, ], zbeta[])
}

gamma1 <- 0

sigZbetaInv <- pow(K, -2)
for(j in 1:dimBeta){
zbeta[j] ~ dnorm(0, sigZbetaInv)
}

tauGamma <- 0.01
for(k in 1:(K-1)){
muGamma[k] <- k - 0.5
gamma[k] ~ dnorm(muGamma[k], tauGamma)T(0,)
}

for(j in 2:dimBeta){
beta[j] <- zbeta[j]/Xsd[j]
}
beta[1] <- zbeta[1] - inprod(zbeta[2:dimBeta], Xm[2:dimBeta]/Xsd[2:dimBeta])
}
"
writeLines(modelString, "model_ordProbit_std.txt")

zbetaInit <- rep(0, dimBeta)
gammaInit <- c(0:(nLevels-2)) + 0.5

dataList = list(nData=nData, K=nLevels, dimBeta = dimBeta, X=X, y = y)
initsList = list(zbeta = zbetaInit, gamma = gammaInit)
jagsModel.std = jags.model(file = "model_ordProbit_std.txt", data = dataList, inits = initsList, n.chains = 3, n.adapt = 1000)
update(jagsModel.std, n.iter = 10000)
codaSamples = coda.samples(jagsModel.std, variable.names = c("gamma", "beta"), n.iter = 10000)

var = colnames(codaSamples[[1]])

#### Fig 7.11 표준화된 자료 사용 시 모수의 경로그림과 자기상관 ####
for(i in 1:length(var))convDiag.plot(codaSamples, var[i])
convDiag(codaSamples)
```